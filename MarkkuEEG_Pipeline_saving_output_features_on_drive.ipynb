{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNEo7sBwVHo3EPURWskFMSM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emi-emi671/EEG-Anonymization/blob/main/MarkkuEEG_Pipeline_saving_output_features_on_drive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Uqs4puJK8-0",
        "outputId": "8ac965c7-825c-4f38-c8c6-9d4ba21bbbf4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kEc-s_pVJ_m5"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/drive/MyDrive/data /content/EEG_DATA\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7I1fRgNALR2A",
        "outputId": "4708e1c4-b0e2-473c-af5c-89c8663f22f4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patient10_MTU207295UUS_t1_anonymized.mat\n",
            "Patient10_MTU207297UUS_t1_anonymized_158849.mat\n",
            "Patient10_MTU207297UUS_t1_anonymized_158865.mat\n",
            "Patient10_MTU207297UUS_t1_anonymized_158873.mat\n",
            "Patient10_MTU207297UUS_t1_anonymized_158877.mat\n",
            "Patient10_MTU207297UUS_t1_anonymized_158884.mat\n",
            "Patient10_MTU207297UUS_t1_anonymized_158927.mat\n",
            "Patient10_MTU207297UUS_t1_anonymized_158936.mat\n",
            "Patient10_MTU207297UUS_t1_anonymized_158940.mat\n",
            "Patient10_MTU207297UUS_t1_anonymized_158952.mat\n",
            "Patient10_MTU207297UUS_t1_anonymized.mat\n",
            "Patient11_MTU207297UUS_t1_anonymized_158964.mat\n",
            "Patient11_MTU207297UUS_t1_anonymized_158971.mat\n",
            "Patient11_MTU207297UUS_t1_anonymized_158973.mat\n",
            "Patient11_MTU207297UUS_t1_anonymized_158985.mat\n",
            "Patient11_MTU207297UUS_t1_anonymized_158990.mat\n",
            "Patient11_MTU207297UUS_t1_anonymized_159010.mat\n",
            "Patient11_MTU207297UUS_t1_anonymized.mat\n",
            "Patient12_MTU207297UUS_t1_anonymized_159014.mat\n",
            "Patient12_MTU207297UUS_t1_anonymized_159018.mat\n",
            "Patient12_MTU207297UUS_t1_anonymized.mat\n",
            "Patient13_MTU207297UUS_t1_anonymized.mat\n",
            "Patient17_MTU207296UUS_t1_anonymized_158837.mat\n",
            "Patient17_MTU207296UUS_t1_anonymized_158844.mat\n",
            "Patient17_MTU207296UUS_t1_anonymized_158854.mat\n",
            "Patient17_MTU207296UUS_t1_anonymized_158856.mat\n",
            "Patient17_MTU207296UUS_t1_anonymized_158861.mat\n",
            "Patient17_MTU207296UUS_t1_anonymized_158866.mat\n",
            "Patient17_MTU207296UUS_t1_anonymized_158874.mat\n",
            "Patient17_MTU207296UUS_t1_anonymized_158879.mat\n",
            "Patient17_MTU207296UUS_t1_anonymized_158882.mat\n",
            "Patient17_MTU207296UUS_t1_anonymized_158886.mat\n",
            "Patient17_MTU207296UUS_t1_anonymized_158890.mat\n",
            "Patient17_MTU207296UUS_t1_anonymized_158896.mat\n",
            "Patient17_MTU207296UUS_t1_anonymized_158901.mat\n",
            "Patient17_MTU207296UUS_t1_anonymized_158903.mat\n",
            "Patient17_MTU207296UUS_t1_anonymized_158905.mat\n",
            "Patient17_MTU207296UUS_t1_anonymized_158908.mat\n",
            "Patient17_MTU207296UUS_t1_anonymized_158912.mat\n",
            "Patient17_MTU207296UUS_t1_anonymized_158916.mat\n",
            "Patient17_MTU207296UUS_t1_anonymized_158919.mat\n",
            "Patient17_MTU207296UUS_t1_anonymized_158922.mat\n",
            "Patient17_MTU207296UUS_t1_anonymized_158928.mat\n",
            "Patient17_MTU207296UUS_t1_anonymized_158931.mat\n",
            "Patient17_MTU207296UUS_t1_anonymized_158953.mat\n",
            "Patient17_MTU207296UUS_t1_anonymized_158956.mat\n",
            "Patient17_MTU207296UUS_t1_anonymized_158959.mat\n",
            "Patient17_MTU207296UUS_t1_anonymized_158967.mat\n",
            "Patient17_MTU207296UUS_t1_anonymized_158977.mat\n",
            "Patient17_MTU207296UUS_t1_anonymized_158982.mat\n",
            "Patient17_MTU207296UUS_t1_anonymized_158987.mat\n",
            "Patient17_MTU207296UUS_t1_anonymized_158994.mat\n",
            "Patient17_MTU207296UUS_t1_anonymized_159005.mat\n",
            "Patient17_MTU207296UUS_t1_anonymized.mat\n",
            "Patient18_MTU207296UUS_t1_anonymized_158945.mat\n",
            "Patient1_MTU200736UUS_t1_anonymized_158848.mat\n",
            "Patient1_MTU200736UUS_t1_anonymized_158870.mat\n",
            "Patient1_MTU200736UUS_t1_anonymized_158883.mat\n",
            "Patient1_MTU200736UUS_t1_anonymized_158897.mat\n",
            "Patient1_MTU200736UUS_t1_anonymized_158958.mat\n",
            "Patient1_MTU200736UUS_t1_anonymized_158998.mat\n",
            "Patient1_MTU200736UUS_t1_anonymized.mat\n",
            "Patient7_MTU207295UUS_t1_anonymized_158826.mat\n",
            "Patient7_MTU207295UUS_t1_anonymized_158836.mat\n",
            "Patient7_MTU207295UUS_t1_anonymized_158839.mat\n",
            "Patient7_MTU207295UUS_t1_anonymized_158853.mat\n",
            "Patient7_MTU207295UUS_t1_anonymized_158864.mat\n",
            "Patient7_MTU207295UUS_t1_anonymized_158875.mat\n",
            "Patient7_MTU207295UUS_t1_anonymized_158880.mat\n",
            "Patient7_MTU207295UUS_t1_anonymized_158885.mat\n",
            "Patient7_MTU207295UUS_t1_anonymized_158889.mat\n",
            "Patient7_MTU207295UUS_t1_anonymized_158895.mat\n",
            "Patient7_MTU207295UUS_t1_anonymized_158900.mat\n",
            "Patient7_MTU207295UUS_t1_anonymized_158904.mat\n",
            "Patient7_MTU207295UUS_t1_anonymized_158915.mat\n",
            "Patient7_MTU207295UUS_t1_anonymized_158923.mat\n",
            "Patient7_MTU207295UUS_t1_anonymized_158925.mat\n",
            "Patient7_MTU207295UUS_t1_anonymized_158930.mat\n",
            "Patient7_MTU207295UUS_t1_anonymized_158939.mat\n",
            "Patient7_MTU207295UUS_t1_anonymized_158947.mat\n",
            "Patient7_MTU207295UUS_t1_anonymized_158957.mat\n",
            "Patient7_MTU207295UUS_t1_anonymized_158960.mat\n",
            "Patient7_MTU207295UUS_t1_anonymized_158966.mat\n",
            "Patient7_MTU207295UUS_t1_anonymized.mat\n",
            "Patient8_MTU207295UUS_t1_anonymized_158974.mat\n",
            "Patient8_MTU207295UUS_t1_anonymized_158983.mat\n",
            "Patient8_MTU207295UUS_t1_anonymized_158986.mat\n",
            "Patient8_MTU207295UUS_t1_anonymized_158996.mat\n",
            "Patient8_MTU207295UUS_t1_anonymized_159004.mat\n",
            "Patient8_MTU207295UUS_t1_anonymized.mat\n",
            "Patient9_MTU207295UUS_t1_anonymized_158989.mat\n",
            "Patient9_MTU207295UUS_t1_anonymized_158993.mat\n",
            "Patient9_MTU207295UUS_t1_anonymized_159009.mat\n",
            "Patient9_MTU207295UUS_t1_anonymized.mat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy scipy h5py matplotlib pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c8w0tKuKL8P",
        "outputId": "069875c7-20fe-4fc0-bf18-4f0391d9955a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (3.15.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (26.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import glob\n",
        "import numpy as np\n",
        "import h5py\n",
        "import scipy.io as sio\n",
        "from scipy.signal import butter, sosfiltfilt, iirnotch, filtfilt, welch\n",
        "from typing import Dict, List, Tuple, Optional, Literal\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 1) Patient ID extraction + file grouping\n",
        "# ============================================================\n",
        "\n",
        "_PATIENT_REGEX_DEFAULT = r\"^(Patient\\d+)\"\n",
        "\n",
        "def extract_patient_id(filename: str, pattern: str = _PATIENT_REGEX_DEFAULT) -> str:\n",
        "    base = os.path.basename(filename)\n",
        "    m = re.match(pattern, base)\n",
        "    if not m:\n",
        "        raise ValueError(\n",
        "            f\"Could not extract patient id from filename: {base}\\n\"\n",
        "            f\"Regex used: {pattern}\\n\"\n",
        "            f\"Update 'pattern' to match your naming scheme.\"\n",
        "        )\n",
        "    return m.group(1)\n",
        "\n",
        "def group_files_by_patient(folder: str, mat_glob: str = \"*.mat\",\n",
        "                           patient_regex: str = _PATIENT_REGEX_DEFAULT) -> Dict[str, List[str]]:\n",
        "    files = sorted(glob.glob(os.path.join(folder, mat_glob)))\n",
        "    if not files:\n",
        "        raise FileNotFoundError(f\"No files found in {folder} matching {mat_glob}\")\n",
        "\n",
        "    groups: Dict[str, List[str]] = {}\n",
        "    for fp in files:\n",
        "        pid = extract_patient_id(fp, pattern=patient_regex)\n",
        "        groups.setdefault(pid, []).append(fp)\n",
        "\n",
        "    for pid in groups:\n",
        "        groups[pid] = sorted(groups[pid])\n",
        "\n",
        "    return groups\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 2) MATLAB/HDF5 loaders\n",
        "# ============================================================\n",
        "\n",
        "def _numeric_datasets(h5file):\n",
        "    items = []\n",
        "    def visit(name, obj):\n",
        "        if isinstance(obj, h5py.Dataset) and np.issubdtype(obj.dtype, np.number):\n",
        "            items.append((name, obj))\n",
        "    h5file.visititems(visit)\n",
        "    return items\n",
        "\n",
        "def _read_scalar_ref(f: h5py.File, ref):\n",
        "    try:\n",
        "        v = np.asarray(f[ref])[()]\n",
        "        v = np.asarray(v).squeeze()\n",
        "        if v.size == 1 and np.isfinite(v).all():\n",
        "            return float(v)\n",
        "    except Exception:\n",
        "        return None\n",
        "    return None\n",
        "\n",
        "def _detect_fs(f: h5py.File, n_ch: int, default_fs: float) -> float:\n",
        "    if \"#refs#/e/samplingRate\" in f:\n",
        "        ds = f[\"#refs#/e/samplingRate\"]\n",
        "        arr = np.asarray(ds[()]).squeeze()\n",
        "        if arr.ndim == 1 and arr.size == n_ch and np.allclose(arr, arr[0]):\n",
        "            val = float(arr[0])\n",
        "            if 50.0 <= val <= 5000.0:\n",
        "                return val\n",
        "\n",
        "    if \"#refs#/t6/dSamplingRate\" in f:\n",
        "        ds = f[\"#refs#/t6/dSamplingRate\"]\n",
        "        try:\n",
        "            refs = np.asarray(ds[()]).squeeze().reshape(-1)\n",
        "            vals = []\n",
        "            for r in refs:\n",
        "                v = _read_scalar_ref(f, r)\n",
        "                if v is not None:\n",
        "                    vals.append(v)\n",
        "            vals = [v for v in vals if 50.0 <= v <= 5000.0]\n",
        "            if vals:\n",
        "                v0 = float(vals[0])\n",
        "                if all(abs(v - v0) < 1e-6 for v in vals):\n",
        "                    return v0\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    return float(default_fs)\n",
        "\n",
        "def load_eeg_and_fs(mat_path: str, default_fs: float = 256.0, mat_key_fallback: str = \"val\"):\n",
        "    try:\n",
        "        with h5py.File(mat_path, \"r\") as f:\n",
        "            best = None\n",
        "            for path, ds in _numeric_datasets(f):\n",
        "                if ds.ndim != 2:\n",
        "                    continue\n",
        "                r, c = ds.shape\n",
        "                ch, smp = min(r, c), max(r, c)\n",
        "                if not (4 <= ch <= 512 and smp / ch >= 10):\n",
        "                    continue\n",
        "                score = ds.size + (0.7 * ds.size if np.issubdtype(ds.dtype, np.floating) else 0)\n",
        "                if best is None or score > best[0]:\n",
        "                    best = (score, path)\n",
        "\n",
        "            if best is None:\n",
        "                raise RuntimeError(f\"EEG dataset not found in {mat_path}\")\n",
        "\n",
        "            eeg_path = best[1]\n",
        "            eeg = np.asarray(f[eeg_path][()])\n",
        "            if eeg.shape[0] > eeg.shape[1]:\n",
        "                eeg = eeg.T\n",
        "            eeg = eeg.astype(np.float32, copy=False)\n",
        "\n",
        "            fs = _detect_fs(f, n_ch=eeg.shape[0], default_fs=default_fs)\n",
        "\n",
        "        return eeg, fs, eeg_path\n",
        "\n",
        "    except OSError:\n",
        "        d = sio.loadmat(mat_path)\n",
        "        if mat_key_fallback not in d:\n",
        "            raise RuntimeError(f\"'{mat_key_fallback}' not found in {mat_path}. Keys: {list(d.keys())}\")\n",
        "\n",
        "        eeg = d[mat_key_fallback]\n",
        "        if eeg.shape[0] > eeg.shape[1]:\n",
        "            eeg = eeg.T\n",
        "        eeg = eeg.astype(np.float32, copy=False)\n",
        "        fs = float(default_fs)\n",
        "        return eeg, fs, mat_key_fallback\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 3) Preprocessing + Features\n",
        "# ============================================================\n",
        "\n",
        "def preprocess(eeg: np.ndarray, fs: float,\n",
        "               band: Tuple[float, float] = (0.5, 70.0),\n",
        "               notch: Optional[float] = 50.0,\n",
        "               reref: bool = True) -> np.ndarray:\n",
        "    x = eeg.astype(np.float64, copy=False)\n",
        "    nyq = 0.5 * fs\n",
        "    low, high = band\n",
        "    if not (0 < low < high < nyq):\n",
        "        raise ValueError(f\"Bad band {band} for fs={fs} (Nyq={nyq}).\")\n",
        "\n",
        "    sos = butter(4, [low / nyq, high / nyq], btype=\"band\", output=\"sos\")\n",
        "    x = sosfiltfilt(sos, x, axis=1)\n",
        "\n",
        "    if notch is not None:\n",
        "        if not (0 < notch < nyq):\n",
        "            raise ValueError(f\"Bad notch {notch} for fs={fs} (Nyq={nyq}).\")\n",
        "        b, a = iirnotch(notch / nyq, Q=30.0)\n",
        "        x = filtfilt(b, a, x, axis=1)\n",
        "\n",
        "    if reref:\n",
        "        x = x - x.mean(axis=0, keepdims=True)\n",
        "\n",
        "    return x.astype(np.float32, copy=False)\n",
        "\n",
        "def extract_window_features(eeg_prep: np.ndarray, fs: float,\n",
        "                            win_sec: float = 2.0, overlap: float = 0.5):\n",
        "    bands = {\n",
        "        \"delta\": (0.5, 4), \"theta\": (4, 8), \"alpha\": (8, 13),\n",
        "        \"beta\": (13, 30), \"gamma\": (30, 45), \"high_gamma\": (45, 70)\n",
        "    }\n",
        "    n_ch, n_samp = eeg_prep.shape\n",
        "    win = int(round(win_sec * fs))\n",
        "    step = int(round(win * (1 - overlap)))\n",
        "    if win <= 1 or step <= 0:\n",
        "        raise ValueError(\"Bad window parameters; check win_sec/overlap/fs.\")\n",
        "    nper = min(256, win)\n",
        "\n",
        "    def bandpower(f, p, lo, hi):\n",
        "        m = (f >= lo) & (f < hi)\n",
        "        return float(np.trapezoid(p[m], f[m])) if np.any(m) else 0.0\n",
        "\n",
        "    def sef95(f, p):\n",
        "        c = np.cumsum(np.maximum(p, 0.0))\n",
        "        if c[-1] <= 0:\n",
        "            return 0.0\n",
        "        return float(f[np.searchsorted(c, 0.95 * c[-1])])\n",
        "\n",
        "    feat_names = []\n",
        "    for ch in range(n_ch):\n",
        "        feat_names += [f\"ch{ch}_ll\", f\"ch{ch}_rms\", f\"ch{ch}_var\", f\"ch{ch}_zcr\"]\n",
        "        feat_names += [f\"ch{ch}_{b}_bp\" for b in bands]\n",
        "        feat_names += [f\"ch{ch}_sef95\"]\n",
        "\n",
        "    X = []\n",
        "    for s in range(0, n_samp - win + 1, step):\n",
        "        seg = eeg_prep[:, s:s + win]\n",
        "        row = []\n",
        "        for ch in range(n_ch):\n",
        "            x = seg[ch].astype(np.float64, copy=False)\n",
        "            row += [\n",
        "                float(np.sum(np.abs(np.diff(x)))) if x.size > 1 else 0.0,\n",
        "                float(np.sqrt(np.mean(x * x))),\n",
        "                float(np.var(x)),\n",
        "                float(np.mean(x[:-1] * x[1:] < 0)) if x.size > 1 else 0.0,\n",
        "            ]\n",
        "            f, p = welch(x, fs=fs, nperseg=nper, noverlap=nper // 2)\n",
        "            for lo, hi in bands.values():\n",
        "                row.append(bandpower(f, p, lo, hi))\n",
        "            row.append(sef95(f, p))\n",
        "        X.append(row)\n",
        "\n",
        "    return np.asarray(X, dtype=np.float32), feat_names\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 4) Patient aggregation + optional log1p\n",
        "# ============================================================\n",
        "\n",
        "def log1p_bandpower_vector(v: np.ndarray, feature_names: List[str]) -> np.ndarray:\n",
        "    v = v.copy()\n",
        "    bp_idx = [i for i, n in enumerate(feature_names) if \"_bp\" in n]\n",
        "    if bp_idx:\n",
        "        v[bp_idx] = np.log1p(np.maximum(v[bp_idx], 0.0))\n",
        "    return v\n",
        "\n",
        "def aggregate_patient_windows(X_all_windows: np.ndarray, method: str = \"mean\") -> np.ndarray:\n",
        "    if X_all_windows.ndim != 2 or X_all_windows.shape[0] == 0:\n",
        "        raise ValueError(\"Need non-empty window matrix (n_windows, n_features).\")\n",
        "\n",
        "    if method == \"mean\":\n",
        "        return X_all_windows.mean(axis=0)\n",
        "    if method == \"median\":\n",
        "        return np.median(X_all_windows, axis=0)\n",
        "    if method == \"mean_std\":\n",
        "        mu = X_all_windows.mean(axis=0)\n",
        "        sd = X_all_windows.std(axis=0, ddof=0)\n",
        "        return np.concatenate([mu, sd], axis=0)\n",
        "    raise ValueError(\"method must be one of: 'mean', 'median', 'mean_std'\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 5) NEW: Normalizer across patients (zscore / robust / minmax)\n",
        "# ============================================================\n",
        "\n",
        "NormMethod = Literal[\"none\", \"zscore\", \"robust\", \"minmax\"]\n",
        "\n",
        "def fit_normalizer(X: np.ndarray, method: NormMethod):\n",
        "    X = np.asarray(X, dtype=np.float64)\n",
        "\n",
        "    if method == \"none\":\n",
        "        return {\"method\": \"none\"}\n",
        "\n",
        "    if method == \"zscore\":\n",
        "        mean = X.mean(axis=0)\n",
        "        std = X.std(axis=0, ddof=0)\n",
        "        std = np.where(std > 0, std, 1.0)\n",
        "        return {\"method\": \"zscore\", \"mean\": mean, \"std\": std}\n",
        "\n",
        "    if method == \"robust\":\n",
        "        med = np.median(X, axis=0)\n",
        "        q1 = np.quantile(X, 0.25, axis=0)\n",
        "        q3 = np.quantile(X, 0.75, axis=0)\n",
        "        iqr = q3 - q1\n",
        "        iqr = np.where(iqr > 0, iqr, 1.0)\n",
        "        return {\"method\": \"robust\", \"median\": med, \"iqr\": iqr}\n",
        "\n",
        "    if method == \"minmax\":\n",
        "        mn = X.min(axis=0)\n",
        "        mx = X.max(axis=0)\n",
        "        rng = mx - mn\n",
        "        rng = np.where(rng > 0, rng, 1.0)\n",
        "        return {\"method\": \"minmax\", \"min\": mn, \"range\": rng}\n",
        "\n",
        "    raise ValueError(\"Unknown method\")\n",
        "\n",
        "def transform_with_normalizer(X: np.ndarray, params: dict) -> np.ndarray:\n",
        "    X = np.asarray(X, dtype=np.float64)\n",
        "    m = params[\"method\"]\n",
        "\n",
        "    if m == \"none\":\n",
        "        return X.astype(np.float32)\n",
        "\n",
        "    if m == \"zscore\":\n",
        "        return ((X - params[\"mean\"]) / params[\"std\"]).astype(np.float32)\n",
        "\n",
        "    if m == \"robust\":\n",
        "        return ((X - params[\"median\"]) / params[\"iqr\"]).astype(np.float32)\n",
        "\n",
        "    if m == \"minmax\":\n",
        "        return ((X - params[\"min\"]) / params[\"range\"]).astype(np.float32)\n",
        "\n",
        "    raise ValueError(\"Bad normalizer params\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 6) Main: build patient vectors + (optional) normalize\n",
        "# ============================================================\n",
        "\n",
        "def build_patient_feature_vectors(\n",
        "    folder: str,\n",
        "    *,\n",
        "    mat_glob: str = \"*.mat\",\n",
        "    patient_regex: str = _PATIENT_REGEX_DEFAULT,\n",
        "    default_fs: float = 256.0,\n",
        "    mat_key_fallback: str = \"val\",\n",
        "    band: Tuple[float, float] = (0.5, 60.0),\n",
        "    notch: Optional[float] = 50.0,\n",
        "    reref: bool = True,\n",
        "    win_sec: float = 2.0,\n",
        "    overlap: float = 0.5,\n",
        "    agg_method: str = \"mean\",\n",
        "    log1p_bp: bool = True,\n",
        "    normalize: NormMethod = \"none\",   # <-- NEW\n",
        ") -> Tuple[Dict[str, np.ndarray], Dict[str, np.ndarray], List[str], Dict[str, dict], dict]:\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      patient_vectors_raw : dict patient_id -> raw aggregated vector\n",
        "      patient_vectors_norm: dict patient_id -> normalized vector (if normalize != 'none')\n",
        "      feature_names       : list[str]\n",
        "      metadata            : dict\n",
        "      norm_params         : dict (normalizer parameters)\n",
        "    \"\"\"\n",
        "    groups = group_files_by_patient(folder, mat_glob=mat_glob, patient_regex=patient_regex)\n",
        "\n",
        "    patient_vectors_raw: Dict[str, np.ndarray] = {}\n",
        "    metadata: Dict[str, dict] = {}\n",
        "    feat_names_ref: Optional[List[str]] = None\n",
        "\n",
        "    for pid, file_list in groups.items():\n",
        "        windows_all = []\n",
        "        per_file_info = []\n",
        "\n",
        "        for fp in file_list:\n",
        "            eeg, fs, eeg_path = load_eeg_and_fs(fp, default_fs=default_fs, mat_key_fallback=mat_key_fallback)\n",
        "            eeg_prep = preprocess(eeg, fs, band=band, notch=notch, reref=reref)\n",
        "            Xw, feat_names = extract_window_features(eeg_prep, fs, win_sec=win_sec, overlap=overlap)\n",
        "\n",
        "            if feat_names_ref is None:\n",
        "                feat_names_ref = feat_names\n",
        "            elif feat_names != feat_names_ref:\n",
        "                raise ValueError(f\"Feature mismatch detected. File: {fp}\")\n",
        "\n",
        "            windows_all.append(Xw)\n",
        "            per_file_info.append({\n",
        "                \"file\": os.path.basename(fp),\n",
        "                \"path\": fp,\n",
        "                \"fs\": float(fs),\n",
        "                \"eeg_path\": eeg_path,\n",
        "                \"n_windows\": int(Xw.shape[0]),\n",
        "                \"n_channels\": int(eeg.shape[0]),\n",
        "                \"n_samples\": int(eeg.shape[1]),\n",
        "            })\n",
        "\n",
        "        if not windows_all or sum(w.shape[0] for w in windows_all) == 0:\n",
        "          raise ValueError(f\"No valid windows for patient {pid}\")\n",
        "\n",
        "        X_patient_windows = np.vstack(windows_all)\n",
        "        v = aggregate_patient_windows(X_patient_windows, method=agg_method)\n",
        "\n",
        "        # feature name expansion for mean_std\n",
        "        feature_names = feat_names_ref\n",
        "        if agg_method == \"mean_std\":\n",
        "            feature_names = [f\"{n}_mean\" for n in feat_names_ref] + [f\"{n}_std\" for n in feat_names_ref]\n",
        "\n",
        "        if log1p_bp:\n",
        "            v = log1p_bandpower_vector(v, feature_names)\n",
        "\n",
        "        patient_vectors_raw[pid] = v.astype(np.float32, copy=False)\n",
        "        metadata[pid] = {\n",
        "            \"patient_id\": pid,\n",
        "            \"n_files\": len(file_list),\n",
        "            \"files\": per_file_info,\n",
        "            \"total_windows\": int(X_patient_windows.shape[0]),\n",
        "            \"agg_method\": agg_method,\n",
        "        }\n",
        "\n",
        "    if feat_names_ref is None:\n",
        "        raise RuntimeError(\"No features extracted.\")\n",
        "\n",
        "    final_feature_names = feat_names_ref\n",
        "    if agg_method == \"mean_std\":\n",
        "        final_feature_names = [f\"{n}_mean\" for n in feat_names_ref] + [f\"{n}_std\" for n in feat_names_ref]\n",
        "\n",
        "    # ----- normalization across patients (optional) -----\n",
        "    pids_sorted = sorted(patient_vectors_raw.keys())\n",
        "    X_raw = np.stack([patient_vectors_raw[k] for k in pids_sorted])\n",
        "\n",
        "    norm_params = fit_normalizer(X_raw, method=normalize)\n",
        "\n",
        "    if normalize == \"none\":\n",
        "        X_norm = X_raw.astype(np.float32)\n",
        "    else:\n",
        "        X_norm = transform_with_normalizer(X_raw, norm_params)\n",
        "\n",
        "    patient_vectors_norm: Dict[str, np.ndarray] = {}\n",
        "    for i, pid in enumerate(pids_sorted):\n",
        "        patient_vectors_norm[pid] = X_norm[i].astype(np.float32, copy=False)\n",
        "\n",
        "    return patient_vectors_raw, patient_vectors_norm, final_feature_names, metadata, norm_params\n"
      ],
      "metadata": {
        "id": "LwthOAvaNUs-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now test the EEG pipeline**"
      ],
      "metadata": {
        "id": "y1r9FbqSQDxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 5) Example usage (Colab)\n",
        "# ============================================================\n",
        "if __name__ == \"__main__\":\n",
        "    folder = \"/content/EEG_DATA/\"  # change\n",
        "    patient_vectors_raw, patient_vectors_norm, feature_names, meta, norm_params = build_patient_feature_vectors(\n",
        "\n",
        "        folder,\n",
        "        mat_glob=\"*.mat\",\n",
        "        patient_regex=r\"^(Patient\\d+)\",  # adjust if needed\n",
        "        default_fs=256.0,\n",
        "        band=(0.5, 60.0),\n",
        "        notch=40.0,\n",
        "        win_sec=2.0,\n",
        "        overlap=0.5,\n",
        "        agg_method=\"mean\",\n",
        "        log1p_bp=True,\n",
        " #        normalize=\"zscore\", when use multiple patients\n",
        "    )\n",
        "\n",
        "print(\"Patients:\", len(patient_vectors_raw))\n",
        "first_pid = sorted(patient_vectors_raw.keys())[0]\n",
        "print(\"Example patient:\", first_pid, \"raw shape:\", patient_vectors_raw[first_pid].shape)\n",
        "print(\"Example patient:\", first_pid, \"norm shape:\", patient_vectors_norm[first_pid].shape)\n",
        "print(\"Feature count:\", len(feature_names))\n",
        "print(\"Files for\", first_pid, \"=\", meta[first_pid][\"n_files\"], \"Total windows:\", meta[first_pid][\"total_windows\"])\n",
        "print(\"Normalizer method:\", norm_params.get(\"method\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4oWKBxoQDDC",
        "outputId": "85a0ed54-1a5a-4899-a92d-06a0d43ec2a8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patients: 9\n",
            "Example patient: Patient1 raw shape: (363,)\n",
            "Example patient: Patient1 norm shape: (363,)\n",
            "Feature count: 363\n",
            "Files for Patient1 = 7 Total windows: 12619\n",
            "Normalizer method: none\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/drive/MyDrive/EEG_CACHE"
      ],
      "metadata": {
        "id": "qcJl1WwYhWra"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import os\n",
        "CACHE_DIR = \"/content/drive/MyDrive/EEG_CACHE\"\n",
        "\n",
        "CACHE_FILE = os.path.join(CACHE_DIR, \"patient_features_v1.joblib\")\n",
        "\n",
        "joblib.dump(\n",
        "    {\n",
        "        \"patient_vectors_raw\": patient_vectors_raw,\n",
        "        \"patient_vectors_norm\": patient_vectors_norm,\n",
        "        \"feature_names\": feature_names,\n",
        "        \"meta\": meta,\n",
        "        \"norm_params\": norm_params,\n",
        "    },\n",
        "    CACHE_FILE,\n",
        "    compress=3,  # balances speed & size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xu31B6YL31ib",
        "outputId": "7bce5308-0f46-46c9-a485-ea57d18e950d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/EEG_CACHE/patient_features_v1.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Patients:\", len(patient_vectors_raw))\n",
        "first_pid = sorted(patient_vectors_raw.keys())[0]\n",
        "print(\"Example patient:\", first_pid, \"raw shape:\", patient_vectors_raw[first_pid].shape)\n",
        "print(\"Example patient:\", first_pid, \"norm shape:\", patient_vectors_norm[first_pid].shape)\n",
        "print(\"Feature count:\", len(feature_names))\n",
        "print(\"Files for\", first_pid, \"=\", meta[first_pid][\"n_files\"], \"Total windows:\", meta[first_pid][\"total_windows\"])\n",
        "print(\"Normalizer method:\", norm_params.get(\"method\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Na_bpWcK59TO",
        "outputId": "e2102f31-ff1f-47d9-e2ef-0fb8e6506168"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patients: 9\n",
            "Example patient: Patient1 raw shape: (363,)\n",
            "Example patient: Patient1 norm shape: (363,)\n",
            "Feature count: 363\n",
            "Files for Patient1 = 7 Total windows: 12619\n",
            "Normalizer method: none\n"
          ]
        }
      ]
    }
  ]
}